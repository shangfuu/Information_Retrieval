{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR - HW1 Vector Space Model\n",
    "* In this project, we will have  \n",
    "    * 50 Queries  \n",
    "    * 4191 Documents\n",
    "\n",
    "Our goal is to implement a vector space model, and print out the ranking results for all of the queries.\n",
    "https://www.kaggle.com/t/7f84706b7b074267ae314582825fb725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return word vector\n",
    "def open_files(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            q = q.strip(\"\\n\").split(\" \")\n",
    "            for term in q:\n",
    "                query.append(term)\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            d = d.strip(\"\\n\").split(\" \")\n",
    "            for term in d:\n",
    "                doc.append(term)\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sentence\n",
    "def open_files2(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            query.append(q.strip(\"\\n\"))\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            doc.append(d.strip(\"\\n\"))\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(all_dict):\n",
    "    \n",
    "    tf = {}\n",
    "    ni = {}\n",
    "    for name, terms in all_dict.items():\n",
    "        tf[name] = {}\n",
    "        check_term = {}\n",
    "        for term in terms:\n",
    "            # ni\n",
    "            try:\n",
    "                if term not in check_term:\n",
    "                    ni[term] += 1\n",
    "                    check_term[term] = True\n",
    "            except:\n",
    "                ni[term] = 1\n",
    "            # TF\n",
    "            try:\n",
    "#                 tf[name][term] += 1 / len(terms)\n",
    "                tf[name][term] += 1\n",
    "            except:\n",
    "#                 tf[name][term] = 1 / len(terms)\n",
    "                tf[name][term] = 1\n",
    "    \n",
    "    # IDF\n",
    "    idf = {}\n",
    "    # score dict initial\n",
    "    score_dict = {}\n",
    "    # col name\n",
    "    col_name = []\n",
    "    for term, times in ni.items():\n",
    "        # smooth idf :prevent zero divisions\n",
    "        idf[term] = math.log( ((1 + len(all_dict)) / (1 + times)) + 1) \n",
    "        score_dict[term] = 0.0\n",
    "        col_name.append(term)\n",
    "    \n",
    "    # TFIDF\n",
    "    tfidf_dict = {}\n",
    "    tfidf_score = []\n",
    "    # index\n",
    "    index = []\n",
    "    for name, _ in all_dict.items():\n",
    "        index.append(name)\n",
    "        tfidf_dict[name] = {}\n",
    "        for term, tf_score in tf[name].items():\n",
    "            # sublinear_tf: replace tf with 1 + log(tf).\n",
    "            sublinear_tf = (1 + math.log(tf_score))\n",
    "            tfidf_dict[name][term] = sublinear_tf * idf[term]\n",
    "            score_dict[term] = sublinear_tf * idf[term]\n",
    "        tfidf_score.append(list(score_dict.values()))\n",
    "        # Clean up score dict\n",
    "        for term in tf[name].keys():\n",
    "            score_dict[term] = 0.0\n",
    "    tfidf_result = normalize(tfidf_score, norm='l2')\n",
    "    \n",
    "    tfidf_normalize = pd.DataFrame(tfidf_result, columns=col_name, index=index)\n",
    "    return tfidf_dict, tfidf_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(vec1, vec2):\n",
    "    dot = np.dot(vec1, vec2)\n",
    "    norm1 = np.linalg.norm(vec1)\n",
    "    norm2 = np.linalg.norm(vec2)\n",
    "    cos = dot / (norm1 * norm2 + 1)\n",
    "    return cos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "querys_dict, docs_dict = open_files()\n",
    "# print(docs_dict[\"FBIS3-23\"])\n",
    "\n",
    "all_dict = querys_dict.copy()\n",
    "all_dict.update(docs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost time: 27.143171072006226\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tfidf_dict, tfidf_normalize = tfidf(all_dict)\n",
    "print(f\"Cost time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intern</th>\n",
       "      <th>organ</th>\n",
       "      <th>crime</th>\n",
       "      <th>poliomyel</th>\n",
       "      <th>post</th>\n",
       "      <th>polio</th>\n",
       "      <th>hubbl</th>\n",
       "      <th>telescop</th>\n",
       "      <th>achiev</th>\n",
       "      <th>endang</th>\n",
       "      <th>...</th>\n",
       "      <th>hammanskra</th>\n",
       "      <th>mavuso</th>\n",
       "      <th>mzondi</th>\n",
       "      <th>jabulani</th>\n",
       "      <th>14100</th>\n",
       "      <th>14600</th>\n",
       "      <th>holcomb</th>\n",
       "      <th>reigel</th>\n",
       "      <th>verna</th>\n",
       "      <th>caraccilo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.389657</td>\n",
       "      <td>0.544465</td>\n",
       "      <td>0.742782</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.753336</td>\n",
       "      <td>0.339894</td>\n",
       "      <td>0.562989</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689357</td>\n",
       "      <td>0.671312</td>\n",
       "      <td>0.272264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.502012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123090-0026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096396</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.225757</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123189-0136</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034706</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0040</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018760</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05774</td>\n",
       "      <td>0.05774</td>\n",
       "      <td>0.05774</td>\n",
       "      <td>0.05774</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0062</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034635</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035896</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.170943</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.106601</td>\n",
       "      <td>0.106601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4241 rows × 59680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intern     organ     crime  poliomyel      post     polio  \\\n",
       "301            0.389657  0.544465  0.742782   0.000000  0.000000  0.000000   \n",
       "302            0.000000  0.000000  0.000000   0.753336  0.339894  0.562989   \n",
       "303            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "304            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "305            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "...                 ...       ...       ...        ...       ...       ...   \n",
       "LA123090-0026  0.000000  0.096396  0.000000   0.000000  0.000000  0.225757   \n",
       "LA123189-0136  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "LA123190-0040  0.000000  0.000000  0.018760   0.000000  0.000000  0.000000   \n",
       "LA123190-0062  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "LA123190-0065  0.000000  0.000000  0.034635   0.000000  0.035896  0.000000   \n",
       "\n",
       "                  hubbl  telescop    achiev    endang  ...  hammanskra  \\\n",
       "301            0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "302            0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "303            0.689357  0.671312  0.272264  0.000000  ...     0.00000   \n",
       "304            0.000000  0.000000  0.000000  0.502012  ...     0.00000   \n",
       "305            0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "...                 ...       ...       ...       ...  ...         ...   \n",
       "LA123090-0026  0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "LA123189-0136  0.000000  0.000000  0.000000  0.034706  ...     0.00000   \n",
       "LA123190-0040  0.000000  0.000000  0.000000  0.000000  ...     0.05774   \n",
       "LA123190-0062  0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "LA123190-0065  0.000000  0.000000  0.000000  0.000000  ...     0.00000   \n",
       "\n",
       "                mavuso   mzondi  jabulani     14100     14600   holcomb  \\\n",
       "301            0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "302            0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "303            0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "304            0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "305            0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "...                ...      ...       ...       ...       ...       ...   \n",
       "LA123090-0026  0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "LA123189-0136  0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "LA123190-0040  0.05774  0.05774   0.05774  0.000000  0.000000  0.000000   \n",
       "LA123190-0062  0.00000  0.00000   0.00000  0.000000  0.000000  0.000000   \n",
       "LA123190-0065  0.00000  0.00000   0.00000  0.106601  0.106601  0.170943   \n",
       "\n",
       "                 reigel     verna  caraccilo  \n",
       "301            0.000000  0.000000   0.000000  \n",
       "302            0.000000  0.000000   0.000000  \n",
       "303            0.000000  0.000000   0.000000  \n",
       "304            0.000000  0.000000   0.000000  \n",
       "305            0.000000  0.000000   0.000000  \n",
       "...                 ...       ...        ...  \n",
       "LA123090-0026  0.000000  0.000000   0.000000  \n",
       "LA123189-0136  0.000000  0.000000   0.000000  \n",
       "LA123190-0040  0.000000  0.000000   0.000000  \n",
       "LA123190-0062  0.000000  0.000000   0.000000  \n",
       "LA123190-0065  0.106601  0.106601   0.106601  \n",
       "\n",
       "[4241 rows x 59680 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector space model\n",
    "把算出來的COSINE SIM排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost time: 9.94819188117981\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "sim_dict = {}\n",
    "sorted_sim_dict = {}\n",
    "for fqname in querys_dict.keys():\n",
    "    sim_dict[fqname] = {}\n",
    "    query_vec = []\n",
    "    query_term = list(tfidf_dict[fqname].keys())\n",
    "    for term in query_term:\n",
    "        query_vec.append(tfidf_normalize.loc[fqname, term])\n",
    "    for fdname in docs_dict.keys():\n",
    "        doc_vec = []\n",
    "        for term in query_term:\n",
    "            doc_vec.append(tfidf_normalize.loc[fdname, term])\n",
    "        sim_dict[fqname][fdname] = cosine(query_vec, doc_vec)\n",
    "    sorted_sim_dict[fqname] = sorted(sim_dict[fqname], key=sim_dict[fqname].get, reverse=True)\n",
    "\n",
    "print(f\"Cost time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FBIS3-23986', 'FBIS3-19199', 'FBIS3-55219', 'FBIS3-19646', 'FBIS3-21961']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_sim_dict['301'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"result.txt\"):\n",
    "    os.remove(\"result.txt\")\n",
    "    \n",
    "with open(\"result.txt\", \"w\") as ofile:\n",
    "    ofile.write(\"Query,RetrievedDocuments\\n\")\n",
    "    for query_name, score_list in sorted_sim_dict.items():\n",
    "        ofile.write(query_name + \",\")\n",
    "        for score in score_list:\n",
    "            ofile.write(score + \" \")\n",
    "        ofile.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
