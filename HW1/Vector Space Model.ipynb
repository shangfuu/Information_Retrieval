{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR - HW1 Vector Space Model\n",
    "* In this project, we will have  \n",
    "    * 50 Queries  \n",
    "    * 4191 Documents\n",
    "\n",
    "Our goal is to implement a vector space model, and print out the ranking results for all of the queries.\n",
    "https://www.kaggle.com/t/7f84706b7b074267ae314582825fb725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "# from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return word vector\n",
    "def open_files(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            q = q.strip(\"\\n\").split(\" \")\n",
    "            for term in q:\n",
    "                query.append(term)\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            d = d.strip(\"\\n\").split(\" \")\n",
    "            for term in d:\n",
    "                doc.append(term)\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sentence\n",
    "def open_files2(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            query.append(q.strip(\"\\n\"))\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            doc.append(d.strip(\"\\n\"))\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(all_dict):\n",
    "    start = time.time()\n",
    "    \n",
    "    tf = {}\n",
    "    # sublinear_tf: replace tf with 1 + log(tf).\n",
    "    ni = {}\n",
    "    for name, terms in all_dict.items():\n",
    "        tf[name] = {}\n",
    "        for term in terms:\n",
    "            # ni\n",
    "            try:\n",
    "                ni[term] += 1\n",
    "            except:\n",
    "                ni[term] = 1\n",
    "            # TF\n",
    "            try:\n",
    "                tf[name][term] += 1 / len(terms)\n",
    "            except:\n",
    "                tf[name][term] = 1 / len(terms)\n",
    "    \n",
    "    print(time.time() - start)\n",
    "    start = time.time()\n",
    "    \n",
    "    tfidf = {}\n",
    "    for term, times in ni.items():\n",
    "        # IDF :prevent zero divisions\n",
    "        smooth_idf = math.log( (1 + len(all_dict)) / (1 + ni[term]) ) + 1\n",
    "        # TF-IDF\n",
    "        for name, _ in all_dict.items():\n",
    "            tfidf[name] = {}\n",
    "            try:\n",
    "                sublinear_tf = 1 + math.log(tf[name][term])\n",
    "                tfidf[name][term] = sublinear_tf * smooth_idf\n",
    "            except:\n",
    "#                 tfidf[name][term] = 0\n",
    "                sublinear_tf = 1\n",
    "                tfidf[name][term] = sublinear_tf * smooth_idf\n",
    "    \n",
    "    print(len(ni))\n",
    "    print(time.time() - start)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector space model\n",
    "把算出來的COSINE SIM排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))   \n",
    "    norm1 = math.sqrt(sum(v1 * v1 for v1 in vec1))\n",
    "    norm2 = math.sqrt(sum(v2 * v2 for v2 in vec2))\n",
    "    \n",
    "    cos_sim = dot / (norm1 * norm2)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827076298239908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cosine similarity\n",
    "vec1 = [1, 2, 3]\n",
    "vec2 = [3, 4, 5]\n",
    "cosine_similarity(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "querys_dict, docs_dict = open_files()\n",
    "# print(docs_dict[\"FBIS3-23\"])\n",
    "\n",
    "all_dict = querys_dict.copy()\n",
    "all_dict.update(docs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TFIDF = tfidf(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "str1 = 'anbcs ans ans'\n",
    "str2 = 'ans'\n",
    "\n",
    "if str2 in str1:\n",
    "    print(\"test\")\n",
    "\n",
    "if str1.find(str2):\n",
    "    print(\"yee\")\n",
    "\n",
    "## WOW\n",
    "sp1 = str1.split()\n",
    "print(sp1)\n",
    "\n",
    "for s in sp1:\n",
    "    n = sp1.count(s)\n",
    "    print(f\"{s}: {n}\")\n",
    "\n",
    "sp1 = set(sp1)\n",
    "print(sp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = [1,2,3,4]\n",
    "listb = [2,3,4,5]\n",
    "[a*b for a,b in zip(lista,listb)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = {\n",
    "    \"aa\": 13,\n",
    "    \"bb\": 14,\n",
    "}\n",
    "\n",
    "d2 = {\n",
    "    \"cc\": 14,\n",
    "    \"dd\": 15\n",
    "}\n",
    "\n",
    "try:\n",
    "    if d1[\"v\"] == 0:\n",
    "        print(\"HAH\")\n",
    "except:\n",
    "    d1[\"v\"] = 1\n",
    "    \n",
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "math.log(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
