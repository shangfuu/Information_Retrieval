{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR - HW1 Vector Space Model\n",
    "* In this project, we will have  \n",
    "    * 50 Queries  \n",
    "    * 4191 Documents\n",
    "\n",
    "Our goal is to implement a vector space model, and print out the ranking results for all of the queries.\n",
    "https://www.kaggle.com/t/7f84706b7b074267ae314582825fb725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return word vector\n",
    "def open_files(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            q = q.strip(\"\\n\").split(\" \")\n",
    "            for term in q:\n",
    "                query.append(term)\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            d = d.strip(\"\\n\").split(\" \")\n",
    "            for term in d:\n",
    "                doc.append(term)\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sentence\n",
    "def open_files2(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            query.append(q.strip(\"\\n\"))\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            doc.append(d.strip(\"\\n\"))\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf(all_dict):\n",
    "    \n",
    "    tf = {}\n",
    "    ni = {}\n",
    "    for name, terms in all_dict.items():\n",
    "        tf[name] = {}\n",
    "        check_term = {}\n",
    "        for term in terms:\n",
    "            # ni\n",
    "            try:\n",
    "                if term not in check_term:\n",
    "                    ni[term] += 1\n",
    "                    check_term[term] = True\n",
    "            except:\n",
    "                ni[term] = 1\n",
    "            # TF\n",
    "            try:\n",
    "#                 tf[name][term] += 1 / len(terms)\n",
    "                tf[name][term] += 1\n",
    "            except:\n",
    "#                 tf[name][term] = 1 / len(terms)\n",
    "                tf[name][term] = 1\n",
    "    \n",
    "    # IDF\n",
    "    idf = {}\n",
    "    # score dict initial\n",
    "    score_dict = {}\n",
    "    # col name\n",
    "    col_name = []\n",
    "    for term, times in ni.items():\n",
    "        # smooth idf :prevent zero divisions\n",
    "        idf[term] = math.log( ((1 + len(all_dict)) / (1 + times)) ) + 1\n",
    "        score_dict[term] = 0.0\n",
    "        col_name.append(term)\n",
    "    \n",
    "    # TFIDF\n",
    "    tfidf_dict = {}\n",
    "    tfidf_score = []\n",
    "    # index\n",
    "    index = []\n",
    "    for name, _ in all_dict.items():\n",
    "        index.append(name)\n",
    "        tfidf_dict[name] = {}\n",
    "        for term, tf_score in tf[name].items():\n",
    "            # sublinear_tf: replace tf with 1 + log(tf).\n",
    "            sublinear_tf = (1 + math.log(tf_score))\n",
    "            tfidf_dict[name][term] = sublinear_tf * idf[term]\n",
    "            score_dict[term] = sublinear_tf * idf[term]\n",
    "        tfidf_score.append(list(score_dict.values()))\n",
    "        # Clean up score dict\n",
    "        for term in tf[name].keys():\n",
    "            score_dict[term] = 0.0\n",
    "    tfidf_result = normalize(tfidf_score, norm='l2')\n",
    "    \n",
    "    return tfidf_dict, tfidf_result, col_name, index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector space model\n",
    "把算出來的COSINE SIM排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    dot = sum(v1 * v2 for v1, v2 in zip(vec1, vec2))   \n",
    "    norm1 = math.sqrt(sum(v1 * v1 for v1 in vec1))\n",
    "    norm2 = math.sqrt(sum(v2 * v2 for v2 in vec2))\n",
    "    \n",
    "    cos_sim = dot / (norm1 * norm2)\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9827076298239908"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cosine similarity\n",
    "vec1 = [1, 2, 3]\n",
    "vec2 = [3, 4, 5]\n",
    "cosine_similarity(vec1, vec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "querys_dict, docs_dict = open_files()\n",
    "# print(docs_dict[\"FBIS3-23\"])\n",
    "\n",
    "all_dict = querys_dict.copy()\n",
    "all_dict.update(docs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.85719084739685\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tfidf_dict, tfidf_result, col_name, index = tfidf(all_dict)\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "intern       0.0\n",
       "organ        0.0\n",
       "crime        0.0\n",
       "poliomyel    0.0\n",
       "post         0.0\n",
       "            ... \n",
       "14600        0.0\n",
       "holcomb      0.0\n",
       "reigel       0.0\n",
       "verna        0.0\n",
       "caraccilo    0.0\n",
       "Name: LA072189-0048, Length: 59680, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf = pd.DataFrame(tfidf_result, columns=col_name, index=index)\n",
    "df_tfidf.loc['LA072189-0048', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>intern</th>\n",
       "      <th>organ</th>\n",
       "      <th>crime</th>\n",
       "      <th>poliomyel</th>\n",
       "      <th>post</th>\n",
       "      <th>polio</th>\n",
       "      <th>hubbl</th>\n",
       "      <th>telescop</th>\n",
       "      <th>achiev</th>\n",
       "      <th>endang</th>\n",
       "      <th>...</th>\n",
       "      <th>hammanskra</th>\n",
       "      <th>mavuso</th>\n",
       "      <th>mzondi</th>\n",
       "      <th>jabulani</th>\n",
       "      <th>14100</th>\n",
       "      <th>14600</th>\n",
       "      <th>holcomb</th>\n",
       "      <th>reigel</th>\n",
       "      <th>verna</th>\n",
       "      <th>caraccilo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>0.418991</td>\n",
       "      <td>0.557749</td>\n",
       "      <td>0.716493</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728294</td>\n",
       "      <td>0.379738</td>\n",
       "      <td>0.570427</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.678101</td>\n",
       "      <td>0.662881</td>\n",
       "      <td>0.31744</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.518474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123090-0026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.219452</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123189-0136</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.037941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0040</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0062</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA123190-0065</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038010</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039110</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096748</td>\n",
       "      <td>0.096748</td>\n",
       "      <td>0.156138</td>\n",
       "      <td>0.096748</td>\n",
       "      <td>0.096748</td>\n",
       "      <td>0.096748</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4241 rows × 59680 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 intern     organ     crime  poliomyel      post     polio  \\\n",
       "301            0.418991  0.557749  0.716493   0.000000  0.000000  0.000000   \n",
       "302            0.000000  0.000000  0.000000   0.728294  0.379738  0.570427   \n",
       "303            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "304            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "305            0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "...                 ...       ...       ...        ...       ...       ...   \n",
       "LA123090-0026  0.000000  0.110526  0.000000   0.000000  0.000000  0.219452   \n",
       "LA123189-0136  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "LA123190-0040  0.000000  0.000000  0.020386   0.000000  0.000000  0.000000   \n",
       "LA123190-0062  0.000000  0.000000  0.000000   0.000000  0.000000  0.000000   \n",
       "LA123190-0065  0.000000  0.000000  0.038010   0.000000  0.039110  0.000000   \n",
       "\n",
       "                  hubbl  telescop   achiev    endang  ...  hammanskra  \\\n",
       "301            0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "302            0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "303            0.678101  0.662881  0.31744  0.000000  ...    0.000000   \n",
       "304            0.000000  0.000000  0.00000  0.518474  ...    0.000000   \n",
       "305            0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "...                 ...       ...      ...       ...  ...         ...   \n",
       "LA123090-0026  0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "LA123189-0136  0.000000  0.000000  0.00000  0.037941  ...    0.000000   \n",
       "LA123190-0040  0.000000  0.000000  0.00000  0.000000  ...    0.051888   \n",
       "LA123190-0062  0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "LA123190-0065  0.000000  0.000000  0.00000  0.000000  ...    0.000000   \n",
       "\n",
       "                 mavuso    mzondi  jabulani     14100     14600   holcomb  \\\n",
       "301            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "302            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "303            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "304            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "305            0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "...                 ...       ...       ...       ...       ...       ...   \n",
       "LA123090-0026  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "LA123189-0136  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "LA123190-0040  0.051888  0.051888  0.051888  0.000000  0.000000  0.000000   \n",
       "LA123190-0062  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "LA123190-0065  0.000000  0.000000  0.000000  0.096748  0.096748  0.156138   \n",
       "\n",
       "                 reigel     verna  caraccilo  \n",
       "301            0.000000  0.000000   0.000000  \n",
       "302            0.000000  0.000000   0.000000  \n",
       "303            0.000000  0.000000   0.000000  \n",
       "304            0.000000  0.000000   0.000000  \n",
       "305            0.000000  0.000000   0.000000  \n",
       "...                 ...       ...        ...  \n",
       "LA123090-0026  0.000000  0.000000   0.000000  \n",
       "LA123189-0136  0.000000  0.000000   0.000000  \n",
       "LA123190-0040  0.000000  0.000000   0.000000  \n",
       "LA123190-0062  0.000000  0.000000   0.000000  \n",
       "LA123190-0065  0.096748  0.096748   0.096748  \n",
       "\n",
       "[4241 rows x 59680 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_vec = {}\n",
    "col_name = []\n",
    "for fdname in docs_dict.keys():\n",
    "    docs_vec[fdname] = list(df_tfidf.loc[fdname,:])\n",
    "    col_name.append(fdname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vec = {}\n",
    "row_name = []\n",
    "for fqname in querys_dict.keys():\n",
    "    query_vec[fqname] = list(df_tfidf.loc[fqname,:])\n",
    "    row_name.append(fqname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "float division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1260ae0e085e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mq_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfdname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdocs_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0msim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfqname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfdname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfqname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocs_vec\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfdname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mq_sim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfqname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfdname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0msim_all\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-ee19a6ffcb21>\u001b[0m in \u001b[0;36mcosine_similarity\u001b[1;34m(vec1, vec2)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mnorm2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv2\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvec2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mcos_sim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdot\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnorm1\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnorm2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mZeroDivisionError\u001b[0m: float division by zero"
     ]
    }
   ],
   "source": [
    "sim_dict = {}\n",
    "sim_all = []\n",
    "i = 0\n",
    "for fqname in querys_dict.keys():\n",
    "    sim_dict[fqname] = {}\n",
    "    q_sim = []\n",
    "    for fdname in docs_dict.keys():\n",
    "        sim_dict[fqname][fdname] = cosine_similarity(query_vec[fqname], docs_vec[fdname])\n",
    "        q_sim.append(sim_dict[fqname][fdname])\n",
    "    sim_all.append(q_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_all[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return sentence\n",
    "def my_open_files(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = []\n",
    "    query_list = []\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            query.append(q.strip(\"\\n\"))\n",
    "        querys.append(query)\n",
    "        query_list.append(fname)\n",
    "        fq.close()\n",
    "\n",
    "    docs = []\n",
    "    doc_list = []\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        if fname == 'LA072189-0048':\n",
    "            continue\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            doc.append(d.strip(\"\\n\"))\n",
    "        docs.append(doc)\n",
    "        doc_list.append(fname)\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs, query_list, doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_tfidf(all_input):\n",
    "    col_name = []\n",
    "    all_data_split = []\n",
    "    print(all_input[0][0])\n",
    "    for i in range(len(all_input)):\n",
    "        all_data_split.append(all_input[i][0].split())\n",
    "    \n",
    "    voc_dic = {}\n",
    "    score_dict_list = []\n",
    "    example_dic = {}\n",
    "    for i in range(len(all_data_split)):\n",
    "        score_dic = {}\n",
    "        updated = {}\n",
    "        for j in range(len(all_data_split[i])):\n",
    "            if(voc_dic.get(all_data_split[i][j]) != None):\n",
    "                if all_data_split[i][j] not in updated:\n",
    "                    voc_dic[all_data_split[i][j]] += 1.0\n",
    "                    updated[all_data_split[i][j]] = 1.0\n",
    "            else:\n",
    "                voc_dic[all_data_split[i][j]] = 1.0\n",
    "                updated[all_data_split[i][j]] = 1.0\n",
    "            if score_dic.get(all_data_split[i][j]) == None:\n",
    "                score_dic[all_data_split[i][j]] = 1.0\n",
    "            else:\n",
    "                score_dic[all_data_split[i][j]] += 1.0\n",
    "            example_dic[all_data_split[i][j]] = 0\n",
    "        score_dict_list.append(score_dic)\n",
    "    col_name =list(voc_dic.keys())\n",
    "    \n",
    "    #idf\n",
    "    idf_dic = {}\n",
    "    N = len(all_input)\n",
    "    for voc in voc_dic:\n",
    "        idf_dic[voc] = math.log(1+((N+1)/(voc_dic[voc] +1)))\n",
    "    result = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        for value in score_dict_list[i]:\n",
    "            example_dic[value] = idf_dic[value] * (1+math.log(score_dict_list[i][value]))\n",
    "        score = list(example_dic.values())\n",
    "        result.append(score)\n",
    "        for value in score_dict_list[i]:\n",
    "            example_dic[value] = 0.0\n",
    "    resul_score = normalize(result, norm='l2')\n",
    "    return resul_score, col_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# q, d, ql, dl = my_open_files()\n",
    "# # print(ql[:5])\n",
    "# # print(dl[:5])\n",
    "# # print(q[0])\n",
    "# # print(d[0])\n",
    "# all_input = q + d\n",
    "# tfidf_score, col_name = my_tfidf(all_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_tfidf = pd.DataFrame(tfidf_score, columns=col_name, index=(ql + dl))\n",
    "# df_tfidf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
