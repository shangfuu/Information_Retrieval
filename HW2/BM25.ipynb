{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IR - HW2 BM model\n",
    "* In this project, we will have  \n",
    "    * 50 Queries  \n",
    "    * 4191 Documents\n",
    "* Our goal is to implement a BM model\n",
    "    * BM1\n",
    "    * BM15\n",
    "    * BM11\n",
    "    * BM25\n",
    "    * BM25L\n",
    "\n",
    "https://www.kaggle.com/t/7f84706b7b074267ae314582825fb725\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return word vector\n",
    "def open_files(path_query = \"data/queries\", path_docs = \"data/docs\", extension = \".txt\"):\n",
    "    qlf = open(\"data/query_list.txt\")\n",
    "    dlf = open(\"data/doc_list.txt\")\n",
    "    \n",
    "    querys = {}\n",
    "    for fname in qlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_query, fname + extension)\n",
    "        \n",
    "        fq = open(file)\n",
    "        query = []\n",
    "        for q in fq:\n",
    "            q = q.strip(\"\\n\").split(\" \")\n",
    "            for term in q:\n",
    "                query.append(term)\n",
    "        querys[fname] = query\n",
    "        fq.close()\n",
    "\n",
    "    docs = {}\n",
    "    for fname in dlf:\n",
    "        fname = fname.strip(\"\\n\")\n",
    "        file = os.path.join(path_docs, fname + extension)\n",
    "        \n",
    "        fd = open(file)\n",
    "        doc = []\n",
    "        for d in fd:\n",
    "            d = d.strip(\"\\n\").split(\" \")\n",
    "            for term in d:\n",
    "                doc.append(term)\n",
    "        docs[fname] = doc\n",
    "        fd.close()\n",
    "\n",
    "    dlf.close()\n",
    "    qlf.close()\n",
    "\n",
    "    return querys, docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(all_dict, sublinear=True):\n",
    "    \n",
    "    tf = {}\n",
    "    ni = {}\n",
    "    for name, terms in all_dict.items():\n",
    "        tf[name] = {}\n",
    "        check_term = {}\n",
    "        for term in terms:\n",
    "            # ni\n",
    "            try:\n",
    "                if term not in check_term:\n",
    "                    ni[term] += 1\n",
    "                    check_term[term] = True\n",
    "            except:\n",
    "                ni[term] = 1\n",
    "            # TF\n",
    "            try:\n",
    "                tf[name][term] += 1\n",
    "            except:\n",
    "                tf[name][term] = 1\n",
    "    \n",
    "    # IDF\n",
    "    idf = {}\n",
    "    for term, times in ni.items():\n",
    "        idf[term] = math.log( (len(all_dict) - times + 0.5) / (0.5 + times) )\n",
    "    \n",
    "    if sublinear:\n",
    "        # sublinear_tf: replace tf with 1 + log(tf).\n",
    "        for name, _ in all_dict.items():\n",
    "            for term, tf_score in tf[name].items():\n",
    "                tf[name][term] = (1 + math.log(tf_score))\n",
    "\n",
    "    return tf, idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "querys_dict, docs_dict = open_files()\n",
    "# print(docs_dict[\"FBIS3-23\"])\n",
    "\n",
    "all_dict = querys_dict.copy()\n",
    "all_dict.update(docs_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "tf_dict, idf_dict = tf_idf(all_dict, False)\n",
    "# print(f\"Cost time: {time.time() - start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25 model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25 Formula\n",
    "def bm25(tf_q, tf_d, idf, avgDL, doc, b=0.75, k3=1000, k1=1.2):\n",
    "    bm_weight = 0.0\n",
    "    for i in range(len(tf_q)):\n",
    "        bm_weight += (k1 + 1) * tf_d[i] / (k1 * ((1 - b) + b * len(doc) / avgDL) + tf_d[i]) \\\n",
    "                    * (k3 + 1) * tf_q[i] / (k3 + tf_q[i]) * idf[i]\n",
    "\n",
    "    return bm_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BM25L Formula\n",
    "def bm25L(tf_q, tf_d, idf, avgDL, doc, b=0.75, k3 = 0.5, k1=1.2):\n",
    "    bm_weight = 0.0\n",
    "    for i in range(len(tf_q)):\n",
    "        ctd = tf_d[i] / (1 - b + b * len(doc) / avgDL)\n",
    "        bm_weight += idf[i] * (k1 + 1) * (ctd + k3) / (k1 + ctd + k3)\n",
    "    return bm_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average docs length\n",
    "def avgDocLength(docs):\n",
    "    avgDL = 0\n",
    "    for term in docs.values():\n",
    "        avgDL += len(term)\n",
    "    return avgDL / len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "avgdoclen = avgDocLength(docs_dict)\n",
    "\n",
    "sim_dict = {}\n",
    "sorted_sim_dict = {}\n",
    "for fqname in querys_dict.keys():\n",
    "    sim_dict[fqname] = {}\n",
    "    query_tf = []\n",
    "    idf = []\n",
    "    query_term = querys_dict[fqname]\n",
    "    for term in query_term:\n",
    "        # idf\n",
    "        idf.append(idf_dict[term])\n",
    "        # tf of query\n",
    "        if tf_dict[fqname].get(term) is not None:\n",
    "            query_tf.append(tf_dict[fqname][term])\n",
    "        else:\n",
    "            query_tf.append(0)\n",
    "    for fdname, terms_d in docs_dict.items():\n",
    "        doc_tf = []\n",
    "        # tf of doc\n",
    "        for term in query_term:\n",
    "            if tf_dict[fdname].get(term) is not None:\n",
    "                doc_tf.append(tf_dict[fdname][term])\n",
    "            else:\n",
    "                doc_tf.append(0)\n",
    "        sim_dict[fqname][fdname] = bm25(query_tf, doc_tf, idf, avgdoclen, terms_d, b=0.85, k1=3)\n",
    "    sorted_sim_dict[fqname] = sorted(sim_dict[fqname], key=sim_dict[fqname].get, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"result.txt\"):\n",
    "    os.remove(\"result.txt\")\n",
    "    \n",
    "with open(\"result.txt\", \"w\") as ofile:\n",
    "    ofile.write(\"Query,RetrievedDocuments\\n\")\n",
    "    for query_name, score_list in sorted_sim_dict.items():\n",
    "        ofile.write(query_name + \",\")\n",
    "        for score in score_list:\n",
    "            ofile.write(score + \" \")\n",
    "        ofile.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IR",
   "language": "python",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
